{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"font.size\"] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification via k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générons d’abord des données synthétiques, ou artifcielles, avant de travailler avec des vrais problemes.   Notre modèle génératif sera un modèle de mélange gaussien (GMM, Gaussian Mixture Model): pour chaque classe, nous allons d'abord échantillonner 10 centroïdes différents\n",
    "${\\vec m}_k$ from $\\mathcal{N} ({\\vec 0}, I_2)$, puis choisissez des centroïdes au hasard et échantillonnez les données réelles de\n",
    "$\\mathcal{N} ({\\vec m}_k, \\frac{1}{5} I_2)$.\n",
    "\n",
    "Nous commençons par échantillonner les centroïdes et les tracer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Centroids')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6096568898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Samples 10 centroids for each class from two different bivariate Normal distributions\n",
    "centroids_per_class = 10\n",
    "\n",
    "class0_centroids = [1, 0] + np.random.randn(centroids_per_class, 2)\n",
    "class1_centroids = [0, 1] + np.random.randn(centroids_per_class, 2)\n",
    "\n",
    "# Plot centroids\n",
    "plt.plot(class0_centroids[:, 0], class0_centroids[:, 1], \"o\", markersize=8)\n",
    "plt.plot(class1_centroids[:, 0], class1_centroids[:, 1], \"x\", markersize=8)\n",
    "plt.title(\"Centroids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que nous avons les centroïdes, nous pouvons échantillonner les données réelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Samples')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6096568390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_per_class = 100\n",
    "\n",
    "# Sample actual data sampling from Normal distributions positioned around the centroids\n",
    "class0_labels = np.random.randint(10, size = samples_per_class)\n",
    "class1_labels = np.random.randint(10, size = samples_per_class)\n",
    "\n",
    "class0_samples = class0_centroids[class0_labels, :] + np.sqrt(1. / 5) * np.random.randn(samples_per_class, 2)\n",
    "class1_samples = class1_centroids[class1_labels, :] + np.sqrt(1. / 5) * np.random.randn(samples_per_class, 2)\n",
    "\n",
    "# Plot data\n",
    "plt.plot(class0_samples[:, 0], class0_samples[:, 1], \"o\", markersize=8)\n",
    "plt.plot(class1_samples[:, 0], class1_samples[:, 1], \"x\", markersize=8)\n",
    "plt.title(\"Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C’est le problème que nous voulons résoudre: on nous donne ces points et nous voulons trouver une frontière de décision assurant la généralisation, c’est-à-dire que nous pourrons classer correctement les nouveaux échantillons une fois qu’ils nous auront été fournis.\n",
    "\n",
    "Groupons les données de manière agréable. Pour les problèmes de classification binaire comme celui-ci, la manière dont les données sont arrangées est généralement toujours la même.\n",
    "- une matrice des données $ X $ de taille $ N \\times P $, où $ N $ est le nombre d'échantillons et $ P $ est le nombre de parametres (ou descripteurs/features) (dans notre cas, $ N = 200 $ et $ P = 2 $) ;\n",
    "- un vecteur de label $ y \\in \\{0, 1 \\} ^ N $ indiquant à quelle classe appartient chaque échantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86955776  2.1175616 ]\n",
      " [ 1.58388518 -0.17701124]\n",
      " [ 1.63021156 -0.32393877]\n",
      " [ 0.98420125  0.42699958]\n",
      " [ 0.17200491  0.87042632]\n",
      " [ 0.27256757 -0.38152922]\n",
      " [ 0.56279031 -0.25208383]\n",
      " [ 1.78582817  0.87221825]\n",
      " [ 0.81548683  1.39013469]\n",
      " [-0.60404922  0.62167274]\n",
      " [ 1.17695152 -0.02821225]\n",
      " [ 1.57728334 -0.6354134 ]\n",
      " [ 0.81611532  0.76977617]\n",
      " [ 0.98862519  0.40177963]\n",
      " [ 0.70755159 -0.23147803]\n",
      " [ 1.0096668   0.84903464]\n",
      " [ 0.07270186  1.22599973]\n",
      " [ 1.47984923 -0.36010211]\n",
      " [ 1.26582354 -0.81783978]\n",
      " [ 1.19387153 -0.9215722 ]\n",
      " [ 1.61043107  0.24573056]\n",
      " [ 1.23345804  0.44391232]\n",
      " [ 1.03030162  1.18851096]\n",
      " [ 0.78464461  0.10941625]\n",
      " [ 0.29139696 -0.81201204]\n",
      " [ 1.47071434  0.08308118]\n",
      " [ 2.09349223  0.0399675 ]\n",
      " [ 1.61408468  0.37778633]\n",
      " [-0.00583146  0.58187519]\n",
      " [ 1.23550639  0.32535803]\n",
      " [ 0.84905766  1.69395151]\n",
      " [ 0.89386321  1.99586842]\n",
      " [ 0.41930196 -1.42356842]\n",
      " [ 0.54053276 -0.1618087 ]\n",
      " [ 0.37407359 -1.26829905]\n",
      " [ 1.0319506   0.21699639]\n",
      " [-0.96174695  0.76176841]\n",
      " [ 0.71222843  1.48622415]\n",
      " [-0.03167608  1.01036183]\n",
      " [ 0.18322114 -1.10083909]\n",
      " [ 0.94910105  0.31893881]\n",
      " [ 1.37274869  1.32164676]\n",
      " [ 0.6096395   1.25215242]\n",
      " [ 2.17544103 -0.64381563]\n",
      " [ 0.50157341  1.41747422]\n",
      " [ 0.76150354  0.90535236]\n",
      " [ 1.62882737  0.47601276]\n",
      " [-1.06997622  1.14283299]\n",
      " [ 0.25849242 -0.61291747]\n",
      " [ 0.05938149  0.74639538]\n",
      " [ 0.20041864 -0.79619217]\n",
      " [ 0.79365812 -0.79571449]\n",
      " [-0.26183209 -0.85384027]\n",
      " [ 0.58835545  0.99001329]\n",
      " [ 0.86439916  1.78151485]\n",
      " [ 0.41367106 -0.41667077]\n",
      " [ 2.23123162  0.50076514]\n",
      " [ 1.43538519  0.36612322]\n",
      " [ 1.64980029  1.8132713 ]\n",
      " [ 1.61146973 -0.08004316]\n",
      " [ 0.81535515 -0.72752489]\n",
      " [ 0.62101383 -1.35882338]\n",
      " [ 1.519322    0.15684164]\n",
      " [ 1.7692826  -0.51072874]\n",
      " [ 1.82226492 -0.1040144 ]\n",
      " [ 0.38607121  0.41773818]\n",
      " [-0.56890511  0.34756156]\n",
      " [ 1.37985921 -0.01437726]\n",
      " [ 0.20750233 -1.41710677]\n",
      " [ 0.88045759  0.59460685]\n",
      " [ 1.50798478 -0.04685069]\n",
      " [ 0.75492606  1.53316168]\n",
      " [ 0.40249417  1.13995572]\n",
      " [ 1.58178893 -0.64756361]\n",
      " [ 1.45608226 -1.35686195]\n",
      " [ 0.94523989 -0.80454045]\n",
      " [ 0.1169705  -1.46403981]\n",
      " [ 0.3879173   1.7972035 ]\n",
      " [ 1.72832025 -0.54432165]\n",
      " [ 1.47676665  0.09335276]\n",
      " [ 0.18446506 -0.92614004]\n",
      " [ 0.43461475  1.20912989]\n",
      " [ 0.15235045  0.53100944]\n",
      " [ 1.58993055  2.21877304]\n",
      " [-0.31588838 -0.68659356]\n",
      " [ 1.11155511 -1.05424759]\n",
      " [ 1.99553936 -0.05583811]\n",
      " [ 1.87415823 -0.23284835]\n",
      " [ 1.71625944  0.01856045]\n",
      " [ 2.72181259  1.05496953]\n",
      " [ 0.55511423 -1.44861665]\n",
      " [ 1.25650817  2.28398656]\n",
      " [ 2.24331772  1.17506253]\n",
      " [ 0.94227667  0.01189148]\n",
      " [ 0.32584746 -0.58834988]\n",
      " [ 1.02404615  1.87566255]\n",
      " [ 0.23379936 -0.69123896]\n",
      " [ 0.08536292 -0.42783433]\n",
      " [ 0.56666131  0.14229787]\n",
      " [ 1.96064578  0.30685074]\n",
      " [ 0.02895808  1.09339276]\n",
      " [ 0.02092089  0.55773287]\n",
      " [ 0.39833493  1.96630728]\n",
      " [ 0.50555025  0.17548007]\n",
      " [-0.5110307   2.04777023]\n",
      " [-1.38613252  2.41997272]\n",
      " [-1.77077826  2.95387808]\n",
      " [ 0.90676839  0.11042103]\n",
      " [ 1.13948239  1.45265999]\n",
      " [ 0.57718038  0.7601055 ]\n",
      " [-0.54175377  1.50957345]\n",
      " [ 0.52641233  0.82960775]\n",
      " [-0.41165362  2.31604615]\n",
      " [ 1.75036978 -0.85081882]\n",
      " [ 2.41480116  2.05082048]\n",
      " [ 0.33728603  1.64202823]\n",
      " [ 0.49069104  1.3176495 ]\n",
      " [-0.74532443  1.48745732]\n",
      " [ 0.93181003  0.25369871]\n",
      " [ 0.43266923  1.22959109]\n",
      " [-1.82685272  3.24721117]\n",
      " [ 0.2533708   2.0287506 ]\n",
      " [ 1.06478228  1.16903834]\n",
      " [ 2.01597611  1.53935165]\n",
      " [-0.18237081 -0.15628952]\n",
      " [-0.21293257  0.31407651]\n",
      " [ 0.06958187 -0.57789504]\n",
      " [ 0.25349827  1.40086182]\n",
      " [ 0.64028093  1.1520702 ]\n",
      " [ 1.99759968  1.20160756]\n",
      " [-0.77904461  0.54999576]\n",
      " [-0.07574638 -0.07999486]\n",
      " [-0.50761855  1.61667735]\n",
      " [ 0.76727348  0.49060536]\n",
      " [-0.49527689 -0.00456039]\n",
      " [ 0.06969911  0.7019204 ]\n",
      " [-0.25353659  2.1123254 ]\n",
      " [ 2.06366261  2.08264669]\n",
      " [ 0.95649505 -0.09406271]\n",
      " [-0.65663699  0.4667352 ]\n",
      " [ 0.89097219  0.73079075]\n",
      " [-0.32993084  1.44908982]\n",
      " [ 0.64067162  0.90340596]\n",
      " [-0.15196608  1.33671246]\n",
      " [ 0.16957446  0.78684568]\n",
      " [-0.094054    0.60067417]\n",
      " [-1.33366545  1.24505477]\n",
      " [ 0.08862291  0.23017372]\n",
      " [ 1.54481553  1.43874222]\n",
      " [ 0.75587625 -0.40578187]\n",
      " [ 0.19300377  1.87572011]\n",
      " [ 0.89869291  0.06212956]\n",
      " [-0.17991053 -0.0330406 ]\n",
      " [ 0.5445506   0.25075198]\n",
      " [ 1.77926788  2.03337668]\n",
      " [ 1.86204317  1.53599848]\n",
      " [-0.19340423 -0.07013084]\n",
      " [ 0.57861938  0.99991133]\n",
      " [-0.24577093  1.28734053]\n",
      " [ 0.17964972  0.07007849]\n",
      " [ 0.77633623 -0.4921838 ]\n",
      " [ 0.74877128 -0.77733633]\n",
      " [-0.27142544  0.32366981]\n",
      " [ 0.51285921  0.56360165]\n",
      " [ 2.83127406  1.5594308 ]\n",
      " [ 0.74908317 -0.09648091]\n",
      " [ 2.20802969  1.07797083]\n",
      " [ 0.41502245  1.9884973 ]\n",
      " [ 0.33137489  1.96519143]\n",
      " [ 0.85849655  0.98551812]\n",
      " [-0.64110207  0.93889861]\n",
      " [ 1.34257344  0.28687044]\n",
      " [-0.1137985   1.87609009]\n",
      " [ 0.42955098  1.28881038]\n",
      " [ 0.37980423  0.92979635]\n",
      " [ 0.51678874  1.36293944]\n",
      " [ 0.27715275  1.0217132 ]\n",
      " [-0.60256165  0.67722025]\n",
      " [-1.57261613  3.26524474]\n",
      " [ 0.84722219  0.84952484]\n",
      " [ 0.84148747  1.05234838]\n",
      " [ 0.91385136  0.15145129]\n",
      " [ 0.57119356  0.77799495]\n",
      " [-1.22188383  3.01313344]\n",
      " [-0.30148911  1.35366035]\n",
      " [-0.0411003   1.5894455 ]\n",
      " [-1.46374992  2.59564773]\n",
      " [-0.86192172  1.251573  ]\n",
      " [-0.4892909   1.42245641]\n",
      " [ 1.15382305  1.05093584]\n",
      " [ 0.70256935  1.84610193]\n",
      " [ 0.17732555  0.32815879]\n",
      " [-0.85883811  3.42369589]\n",
      " [ 1.75207258  1.43986243]\n",
      " [ 1.46053034  0.6950277 ]\n",
      " [ 0.28295406  0.96817457]\n",
      " [ 0.33165176  0.84795373]\n",
      " [-0.32938129  0.43571343]\n",
      " [ 0.01238842  1.62396147]\n",
      " [-1.12691829  2.75258781]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((class0_samples, class1_samples))\n",
    "y = np.hstack((np.zeros(samples_per_class), np.ones(samples_per_class)))\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "n_samples, n_features = np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous calculons la matrice de distance, une matrice $ N \\times N $ contenant la distance entre chaque échantillon et tous les autres (en avons-nous vraiment besoin?)\n",
    "\n",
    "**Exercice** : calculez la matrice de distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(X):\n",
    "    # Here goes the algorithm\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ne voulons pas vraiment utiliser les boucles en Python, alors re-ecrivez cette routines sans boucles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = compute_distances(X)\n",
    "%timeit compute_distances(X)\n",
    "print(distances)\n",
    "\n",
    "# Try to create a function without any loop\n",
    "def compute_distances_no_loop(X):\n",
    "    # We don't really wanna use for loops in Python...\n",
    "    return distances\n",
    "\n",
    "distances = compute_distances_no_loop(X)\n",
    "%timeit compute_distances_no_loop(X)\n",
    "print(distances)\n",
    "\n",
    "# Compare your function with one that someone already wrote in C\n",
    "# Look for such a function in the documentation of scipy and replace the ???\n",
    "from ??? import ???\n",
    "distances = ???(X, X)\n",
    "%timeit ???(X, X)\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la matrice de distance, nous pouvons maintenant écrire notre algorithme!\n",
    "\n",
    "**Exercice**: écrivez une fonction qui calcule l'estimation du voisin $ k $ le plus proche pour chaque point de l'ensemble d'apprentissage. Astuce: recherchez la fonction `np.argpartition`. Quelle est l'erreur de formation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.argpartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X, y, k):\n",
    "    # Here goes the algorithm\n",
    "    return estimate\n",
    "\n",
    "est_labels = knn(X, y, 10)\n",
    "print(est_labels)\n",
    "\n",
    "# Let us compute the training error\n",
    "train_error = np.mean(y != est_labels)\n",
    "print(train_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première moitié du vecteur devrait être composée uniquement de 0 et la seconde moitié devrait être composée de 1; nous pouvons voir cependant qu'il y a des erreurs. Laissez-nous les comploter pour essayer de comprendre ce qui se passe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plt.plot(X[y == 0, 0], X[y == 0, 1], \"o\", markersize=8)\n",
    "plt.plot(X[y == 1, 0], X[y == 1, 1], \"x\", markersize=8)\n",
    "\n",
    "# Draw a red circle around misclassified samples\n",
    "errors = (y != est_labels)\n",
    "plt.plot(X[errors, 0], X[errors, 1], \"o\", color=\"red\", markeredgewidth=3, markerfacecolor=\"white\", markersize=12, alpha=0.5)\n",
    "#plt.plot(X[errors, 0], X[errors, 1], \"o\", color=\"red\", mew=3, mfc=\"white\", ms=12, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on pouvait s'y attendre, des erreurs se produisent dans des régions où la majorité des points appartiennent à l'autre classe.\n",
    "\n",
    "Mais que se passe-t-il lorsque nous essayons de classer des points qui ne sont pas dans le set d'entrainement (le training set)? Il y a plusieurs façons d'évaluer cela. Par exemple, nous aurions pu utiliser seulement une partie de nos données dans l'ensemble de formation (environ 80%) et utiliser le reste pour calculer l'erreur dite de test.\n",
    "Puisque dans notre cas cependant le modèle génératif est connu, nous pourrions aussi bien en extraire davantage d’échantillons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample test data from the model\n",
    "testsamples_per_class = 10000\n",
    "\n",
    "class0_testlabels = np.random.randint(10, size = testsamples_per_class)\n",
    "class1_testlabels = np.random.randint(10, size = testsamples_per_class)\n",
    "class0_testsamples = class0_centroids[class0_testlabels, :] + np.sqrt(1. / 5) * np.random.randn(testsamples_per_class, 2)\n",
    "class1_testsamples = class1_centroids[class1_testlabels, :] + np.sqrt(1. / 5) * np.random.randn(testsamples_per_class, 2)\n",
    "\n",
    "X_test = np.vstack((class0_testsamples, class1_testsamples))\n",
    "y_test = np.hstack((np.zeros(testsamples_per_class), np.ones(testsamples_per_class)))\n",
    "\n",
    "# Compute distance matrix between X and X_test\n",
    "distances_test = cdist(X, X_test)\n",
    "print(distances_test)\n",
    "print(np.shape(distances_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test data\n",
    "plt.plot(X_test[y_test == 0, 0], X_test[y_test == 0, 1], \"o\", ms=8)\n",
    "plt.plot(X_test[y_test == 1, 0], X_test[y_test == 1, 1], \"x\", ms=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous écrivons maintenant une fonction similaire à `knn` qui calcule les estimations non pas pour les points du jeu d’entraînement, mais pour les points d’un nouveau * test *."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_test(X_train, y_train, X_test, y_test, k):\n",
    "    # Here goes the algorithm\n",
    "    # The predictions have to be made on X_test from the data from X_train/y_train\n",
    "    return estimate\n",
    "\n",
    "est_testlabels = knn_test(X, y, X_test, y_test, 10)\n",
    "print(est_testlabels)\n",
    "\n",
    "# Let us compute the test error, now\n",
    "print(np.mean(y_test != est_testlabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’un des problèmes que nous rencontrons lorsque nous utilisons les l'algorithme kNN est qu’il faut choisir une valeur pour $ k $ - en principe, on ne sait pas comment le faire!\n",
    "Pour mieux comprendre cela, voyons comment se comportent les erreurs d’entraînement et de test en fonction de $ k $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience functions that compute the training and test errors, given training and test samples\n",
    "def compute_train_error(X, y, k=1):\n",
    "    y_hat = knn(X, y, k)\n",
    "    return np.mean(y != y_hat)\n",
    "    \n",
    "def compute_test_error(X_train, y_train, X_test, y_test, k=1):\n",
    "    y_hat = knn_test(X_train, y_train, X_test, y_test, k)\n",
    "    return np.mean(y_test != y_hat)\n",
    "\n",
    "# Run functions for k belonging to a range of values\n",
    "ks = np.arange(1, 20)\n",
    "train_error = []\n",
    "test_error = []\n",
    "for (i, k) in enumerate(ks):\n",
    "    train_error.append(compute_train_error(X, y, k))\n",
    "    test_error.append(compute_test_error(X, y, X_test, y_test, k))\n",
    "    print(\"k = %d; train error = %g, test error = %g\" % (k, train_error[-1], test_error[-1]))\n",
    "\n",
    "# Plot results\n",
    "plt.plot(ks, train_error, label = \"train\")\n",
    "plt.plot(ks, test_error, label = \"test\")\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$k$\")\n",
    "plt.ylabel(\"misclassification error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est instructif d’utiliser une autre quantité sur l’axe des x au lieu de $k$: le nombre de degrés de liberté $N / k$. En effet, plus le nombre $k$ est grand,   plus le nombre de paramètres effectifs est petit - pensons par exemple à la limite $k = N$ ,  où tout le monde se voit attribuer le meme label!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the experiment above for a different range of values\n",
    "ks = np.r_[np.arange(1, 10), np.arange(10, 150, 30)]\n",
    "train_error = []\n",
    "test_error = []\n",
    "for k in ks:\n",
    "    train_error.append(compute_train_error(X, y, k))\n",
    "    test_error.append(compute_test_error(X, y, X_test, y_test, k))\n",
    "    print(\"k = %d; train error = %g, test error = %g\" % (k, train_error[-1], test_error[-1]))\n",
    "\n",
    "# Plot error as a function of the degrees of freedom\n",
    "plt.plot(len(y) / np.array(ks), train_error, \"-o\", label = \"train\")\n",
    "plt.plot(len(y) / np.array(ks), test_error, \"-o\", label = \"test\")\n",
    "plt.legend()\n",
    "plt.xlabel(r\"degrees of freedom $N / k$\")\n",
    "plt.ylabel(\"misclassification error\")\n",
    "plt.ylim((0.0, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce graphique rend explicite le fameux * compromis biais-variance * qui apparaît dans toutes les études statistiques. Si nous avons plus de paramètres, nous pouvons obtenir une erreur d’entraînement réduite, mais l’erreur de test (par analogie, de généralisation) augmente en fait, ce qui signifie que nous sur-ajustons (over-fitting en anglais)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S'il vous reste du temps, vous pouvez refaire un test similaire, mais en utilisant la cross-validation (au lieu de juste utiliser un train/test set). Il peut être intéressant de regarder dans la librairie scikit-learn une fonction afin de séparer vos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Python library for Machine Learning: scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez peut-être remarqué que l'exécution de notre implémentation $ k $ -NN pour 20000 échantillons commençait déjà à sembler un peu lente… C'est parce qu'elle n'est pas vraiment optimisée. Si nous voulions que les choses soient rapides, nous devrions recourir à du code C, en utilisant des extensions Python telles que Cython ou ctypes (c'est en fait ce que font pour nous des paquets tels que Numpy et Scipy).\n",
    "De plus, nous avons fait les choses très naïvement - par exemple, il n’est pas nécessaire de calculer la matrice de distance complète si on utilise des structures de données appropriées telles que kd-trees, etc.\n",
    "\n",
    "Heureusement pour nous, il y a des gens qui ont déjà écrit des versions optimisées de la plupart des algorithmes d'apprentissage automatique standard! L'un des package les. plus populaire est le projet scikit-learn, wui a débuté sous le nom de scikits.learn, un projet Google Summer of Code de David Cournapeau.  Elle est développée par de nombreux contributeurs, et notamment dans le monde académique par des instituts français d'enseignement supérieur et de recherche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scikit-learn website](sklearn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons maintenant comment fonctionne l'implémentation k-NN de scikit-learn. Une chose intéressante à propos de scikit-learn est qu’ils ont de nombreux exemples disponibles en ligne. Nous pouvons donc simplement rechercher quelque chose de similaire à ce que nous essayons de faire. Pour la classification k-NN en particulier, il y a cette: http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "clf = neighbors.KNeighborsClassifier(10)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et fait! Avec seulement trois lignes de code, nous avons pu répéter tout ce que nous avions fait jusqu'à présent. Voyons si nous obtenons la même erreur d’entraînement que précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = np.mean(y != clf.predict(X))\n",
    "test_error = np.mean(y_test != clf.predict(X_test))\n",
    "#train_error = 1. - clf.score(X, y)\n",
    "#test_error = 1. - clf.score(X_test, y_test)\n",
    "\n",
    "print(\"train/test error (for k = 10): %g/%g\" % (train_error, test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque les choses sont optimisées ici, nous pouvons même faire des choses plus cool, comme tracer les limites de décision réelles. Pour ce faire, générons une grille et calculons l'estimation pour chaque point de cette grille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid\n",
    "xx, yy = np.meshgrid(np.linspace(-5, 5, 101), np.linspace(-5, 5, 101))\n",
    "zz = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Do some plotting\n",
    "zz = zz.reshape(xx.shape)\n",
    "plt.pcolormesh(xx, yy, zz, cmap = \"coolwarm\", alpha = 0.2)\n",
    "plt.plot(X[y == 0, 0], X[y == 0, 1], \"o\", markersize=8)\n",
    "plt.plot(X[y == 1, 0], X[y == 1, 1], \"x\", markersize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the best value of $k$ by cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une façon de déterminer la \"meilleure\" valeur de $ k $ consiste à partitionner notre ensemble de données en deux (ensembles de formation et de validation), puis à ajuster sa valeur de manière à minimiser l’erreur de validation (nous avons ensuite besoin d’un troisième ensemble permettant de calculer les valeurs). erreur de test - ne jamais ajuster vos paramètres et calculer l'erreur de test en utilisant le même ensemble!)\n",
    "\n",
    "Cependant, cela ne nous fournit pas de bonnes statistiques car le partitionnement n’est effectué qu’une seule fois; une meilleure façon de le faire consiste à partitionner le jeu de données à plusieurs reprises et à recalculer le score. C'est l'idée derrière la validation croisée.\n",
    "\n",
    "scikit-learn a de belles fonctions pratiques pour effectuer une validation croisée (cross-validation) a nous proposer. Nous l'utiliserons souvent par la suite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up the grid search\n",
    "parameters = [{'n_neighbors': np.arange(1, 20)}]\n",
    "clf = GridSearchCV(neighbors.KNeighborsClassifier(n_neighbors = 1), parameters)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Print results\n",
    "print(clf.best_params_)\n",
    "print(clf.cv_results_[\"mean_test_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons comment cela fonctionne sur le test-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = np.mean(y != clf.predict(X))\n",
    "test_error = np.mean(y_test != clf.predict(X_test))\n",
    "print(\"train/test error (for optimal k): %g/%g\" % (train_error, test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification on real datasets: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, laissez-nous travailler avec un vrai jeu de données! Si vous avez déjà étudié un peu de machine learning et de statistiques, vous connaissez probablement le jeu de données MNIST composé de chiffres manuscrits. C'est l'un des ensembles de données les plus célèbres utilisés pour l'analyse comparative des algorithmes de classification et de classification.\n",
    "\n",
    "Il est également inclus dans scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetons un coup d'oeil aux données pour voir à quoi elles ressemblent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data\n",
    "y = mnist.target\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "n_samples, n_features = np.shape(X)\n",
    "\n",
    "# Plot a sample\n",
    "plt.imshow(X[20000, :].reshape((int(np.sqrt(n_features)), -1)), cmap=\"gray\")\n",
    "\n",
    "# Partition set into train/test\n",
    "samples = np.random.randint(60000, size = 1000)\n",
    "X_train, y_train = X[samples, :], y[samples]\n",
    "X_test, y_test = X[60000:, :], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_error = 1. - clf.score(X_train, y_train)\n",
    "test_error = 1. - clf.score(X_test, y_test)\n",
    "print(\"train/test error: %g/%g\" % (train_error, test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce n'est pas mauvais...   mais pas tellement bon non plus! Ce n'est pas tres rapide pour commencer... Vous pouvez essayer d'augmenter le nombre d'elements dans le trainign set (ici seulement 1000). Regardons les échantillons mal classés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errors = np.where(y_train != clf.predict(X_train))\n",
    "print(errors)\n",
    "\n",
    "from random import sample\n",
    "nums=sample(list(errors[0]),4)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "axs[0, 0].imshow(X[nums[0], :].reshape((int(np.sqrt(n_features)), -1)), cmap=\"gray\")\n",
    "axs[0, 0].set_title(\"predicted label: %d\" % (clf.predict(X_train[nums[0], :].reshape(1, -1))))\n",
    "axs[0, 1].imshow(X[nums[1], :].reshape((int(np.sqrt(n_features)), -1)), cmap=\"gray\")\n",
    "axs[0, 1].set_title(\"predicted label: %d\" % (clf.predict(X_train[nums[1], :].reshape(1, -1))))\n",
    "axs[1, 0].imshow(X[nums[2], :].reshape((int(np.sqrt(n_features)), -1)), cmap=\"gray\")\n",
    "axs[1, 0].set_title(\"predicted label: %d\" % (clf.predict(X_train[nums[2], :].reshape(1, -1))))\n",
    "axs[1, 1].imshow(X[nums[3], :].reshape((int(np.sqrt(n_features)), -1)), cmap=\"gray\")\n",
    "axs[1, 1].set_title(\"predicted label: %d\" % (clf.predict(X_train[nums[3], :].reshape(1, -1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auparavant, nous n'exécutions $ k $ -NN que sur deux dimensions; maintenant nos vecteurs sont beaucoup plus gros, ils ont en réalité 768 dimensions. On s'attend à ce que les méthodes locales telles que $ k $ -NN ne fonctionnent pas aussi bien une fois que nous sommes passés à de grandes dimensions. Pourquoi donc?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exercice** : Nous allons utiliser le dataset \"diabete\", que vous pouvez telecharger ici: https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Load the dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "#Print the first 5 rows of the dataframe.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create numpy arrays for features and target\n",
    "X = df.drop('Outcome',axis=1).values\n",
    "y = df['Outcome'].values\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparons les données au hasard en un ensemble d’entraînement et de test.\n",
    "\n",
    "Nous allons adapter / former un classifieur sur l'ensemble d'entraînement et faire des prédictions sur l'ensemble d'essai. Ensuite, nous comparerons les prévisions avec les étiquettes connues.\n",
    "\n",
    "Scikit-learn permet de scinder les données en train et en ensembles de test à l’aide de la méthode train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez maintenant le knn classifier pour prediure le diagnostique d'un diabete a partir des données cliniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
